from __future__ import annotations

from pathlib import Path
import sys
import streamlit as st
import numpy as np
import cv2
from PIL import Image

PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))
CHECKPOINT_DIR = PROJECT_ROOT / "models" / "checkpoints"

from src.inference.predictor import EmotionPredictor
from src.inference.face_detector import detect_and_crop_largest_face
from src.inference.labels import EMOTION_LABELS_EN, EMOTION_LABELS_JA


@st.cache_resource
def load_predictor(model_type):
    if model_type == "resnet":
        ckpt = CHECKPOINT_DIR / "best_resnet_fer2013.pth"
    else:
        pass

    predictor = EmotionPredictor(
        model_type=model_type,
        checkpoint_path=str(ckpt),
        device=None
    )
    return predictor


def pil_to_bgr(image):
    rgb = np.array(image)
    bgr = rgb[:, :, ::-1]
    return bgr


def draw_box_and_label(image_bgr, box, label_en, score):

    annotated = image_bgr.copy()
    x, y, w, h = box.as_tuple()

    cv2.rectangle(annotated, (x, y), (x + w, y + h), (0, 255, 0), 2)

    text = f"{label_en} ({score:.2%})"
    cv2.putText(
        img=annotated,
        text=text,
        org=(x, y - 10),
        fontFace=cv2.FONT_HERSHEY_SIMPLEX,
        fontScale=1.1,
        color=(0, 255, 0),
        thickness=4,
        lineType=cv2.LINE_AA,
    )

    return annotated


def render_sidebar():
    st.sidebar.header("è¨­å®š")

    model_labels = {
        "resnet": "ResNet-18",
    }

    model_type = st.sidebar.selectbox(
        "ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—",
        options=list(model_labels.keys()),
        format_func=lambda k: model_labels[k],
    )

    return model_type


def get_input_image():
    input_mode = st.radio(
        "å…¥åŠ›æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„",
        options=["ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "Webã‚«ãƒ¡ãƒ©"],
        horizontal=True,
    )

    if input_mode == "ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
        file = st.file_uploader(
            "é¡”ãŒå†™ã£ãŸç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            type=["jpg", "jpeg", "png"]
            )
        if file is None:
            return None
        img = Image.open(file).convert("RGB")
        st.image(img, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ", use_container_width=True)
        return img

    camera_image = st.camera_input("Webã‚«ãƒ¡ãƒ©ã§æ’®å½±")
    if camera_image is None:
        return None
    img = Image.open(camera_image).convert("RGB")
    st.image(img, caption="æ’®å½±ç”»åƒ", use_container_width=True)
    return img


def run_inference_flow(uploaded_image, model_type):
    # loading model
    try:
        predictor = load_predictor(model_type)
    except FileNotFoundError as e:
        st.error(
            f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n{e}\n"
            "train.py ã§å­¦ç¿’ã‚’è¡Œã„ã€.pth ã‚’"
            "models/checkpoints/ ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚"
        )
        return

    # 2) detecting face
    bgr_image = pil_to_bgr(uploaded_image)
    box, face_img = detect_and_crop_largest_face(bgr_image, bgr=True)
    if face_img is None:
        st.error("é¡”ãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ç”»åƒã§è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
        return

    # 3) inference
    result = predictor.predict_from_ndarray(face_img, bgr=True)
    class_id = result["class_id"]
    label_ja = result["label_ja"]
    label_en = result["label_en"]
    probs = result["probs"]
    confidence = probs[class_id]

    st.subheader("æ¨è«–çµæœ")
    st.markdown(
        f"**æ„Ÿæƒ…:** {label_ja}ï¼ˆ{label_en}ï¼‰  \n"
        f"**ç¢ºä¿¡åº¦:** {confidence:.2%}"
    )

    # 4) graph
    st.write("å„æ„Ÿæƒ…ã‚¯ãƒ©ã‚¹ã®ç¢ºç‡:")
    prob_dict = {
        f"{EMOTION_LABELS_JA[i]} ({EMOTION_LABELS_EN[i]})": probs[i]
        for i in range(len(probs))
    }
    st.bar_chart(prob_dict)

    # 5) updating image
    st.write("æ¤œå‡ºã•ã‚ŒãŸé¡”ã¨æ¨è«–çµæœ:")
    annotated_bgr = draw_box_and_label(bgr_image, box, label_en, confidence)
    annotated_rgb = annotated_bgr[:, :, ::-1]
    st.image(
        annotated_rgb,
        use_container_width=True
        )


def main():
    st.set_page_config(
        page_title="Facial Expression Recognition",
        page_icon="ğŸ« "
        )
    st.title("è¡¨æƒ…èªè­˜ã‚¢ãƒ—ãƒª")
    st.write("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ or Webã‚«ãƒ¡ãƒ©ã‹ã‚‰é¡”ã®æ„Ÿæƒ…ã‚’æ¨å®šã—ã¾ã™ã€‚\n"
             "ç”»åƒã‚„å†™çœŸãŒä¿å­˜ã•ã‚Œã‚‹äº‹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

    model_type = render_sidebar()
    uploaded_image = get_input_image()

    if st.button("è¡¨æƒ…ã‚’æ¨å®šã™ã‚‹"):
        if uploaded_image is None:
            st.warning("å…ˆã«ç”»åƒã‚’ç”¨æ„ã—ã¦ãã ã•ã„ã€‚")
            return
        run_inference_flow(uploaded_image, model_type)



if __name__ == "__main__":
    main()
